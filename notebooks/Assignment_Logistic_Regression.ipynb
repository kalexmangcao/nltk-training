{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment-Logistic-Regression.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "mP9vWfSRWPwo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Assignment(Logistic Regression)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zD65LrO0WVJx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QPOJu9GKWaQ0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HKr8iC7RWfbA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = load_iris().data\n",
        "y = load_iris().target\n",
        "#from keras.utils import to_categorical\n",
        "#y = to_categorical(y_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mY53HJN6WffX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#[batch size,4]\n",
        "input_features = tf.placeholder(dtype = tf.float32, \n",
        "                                shape = [None, x.shape[1]]) #None, batch size\n",
        "#[batch size,3]\n",
        "input_labels = tf.placeholder(dtype = tf.float32,\n",
        "                             shape = [None, 3])\n",
        "#[4, 3]\n",
        "weights = tf.Variable(tf.random_normal(shape = [x.shape[1], 3]))\n",
        "#[3]\n",
        "biases = tf.Variable(tf.random_normal(shape = [3]))\n",
        "\n",
        "#[batch size, 4] x [4, 3] = [batch size, 3]\n",
        "#[batch size, 3] x [3] = [batch size, 3]\n",
        "log_model = tf.nn.softmax(tf.add(tf.matmul(input_features, weights), biases)) #in matmul(matrix multiply), input_features must be first on the input \n",
        "\n",
        "#average (wx+b - y)**2\n",
        "loss = tf.reduce_mean(-tf.reduce_sum(input_labels*tf.log(log_model), reduction_indices=1))\n",
        "train_op = tf.train.GradientDescentOptimizer(learning_rate = 0.001).minimize(loss)  #objextive function -> minimize "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BpoCXDlwWfkB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f4z5K8y6Wfm3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-Px0-N80Wfic",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def next_batch(batch_size, features, labels):\n",
        "  indices = np.arange(start = 0, stop = features.shape[0])\n",
        "  np.random.shuffle(indices)\n",
        "  indices = indices[:batch_size]\n",
        "  return features[indices], labels[indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qhxAPv_YWfeJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "4be6737d-42c4-412e-de34-a004a92cb4b2"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 30\n",
        "for epoch in range(30):\n",
        "  for index in range(int(x.shape[0] / batch_size)):\n",
        "    mini_batch_x, mini_batch_y = next_batch(batch_size = batch_size,\n",
        "                                           features = x,\n",
        "                                           labels = y)\n",
        "    \n",
        "    from keras.utils import to_categorical\n",
        "    mini_batch_y = to_categorical(mini_batch_y)\n",
        "    _, train_loss = sess.run([train_op, loss], feed_dict = {\n",
        "        input_features: mini_batch_x,\n",
        "        input_labels: mini_batch_y\n",
        "    })\n",
        "  print('Epoch {}, loss: {}'.format(epoch,train_loss))"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, loss: 2.422292470932007\n",
            "Epoch 1, loss: 2.4922797679901123\n",
            "Epoch 2, loss: 2.1838808059692383\n",
            "Epoch 3, loss: 1.9535000324249268\n",
            "Epoch 4, loss: 2.253782033920288\n",
            "Epoch 5, loss: 1.6059092283248901\n",
            "Epoch 6, loss: 1.8581937551498413\n",
            "Epoch 7, loss: 1.9235049486160278\n",
            "Epoch 8, loss: 1.5139073133468628\n",
            "Epoch 9, loss: 1.386810541152954\n",
            "Epoch 10, loss: 2.004849910736084\n",
            "Epoch 11, loss: 1.495423674583435\n",
            "Epoch 12, loss: 1.7196141481399536\n",
            "Epoch 13, loss: 1.5950927734375\n",
            "Epoch 14, loss: 1.606449842453003\n",
            "Epoch 15, loss: 1.130372166633606\n",
            "Epoch 16, loss: 1.2374303340911865\n",
            "Epoch 17, loss: 1.6138043403625488\n",
            "Epoch 18, loss: 1.2353394031524658\n",
            "Epoch 19, loss: 1.4077640771865845\n",
            "Epoch 20, loss: 1.1165473461151123\n",
            "Epoch 21, loss: 1.387500286102295\n",
            "Epoch 22, loss: 1.0578968524932861\n",
            "Epoch 23, loss: 1.275704026222229\n",
            "Epoch 24, loss: 1.080398678779602\n",
            "Epoch 25, loss: 1.0684791803359985\n",
            "Epoch 26, loss: 1.1703879833221436\n",
            "Epoch 27, loss: 1.1518994569778442\n",
            "Epoch 28, loss: 1.0802282094955444\n",
            "Epoch 29, loss: 1.0989081859588623\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}